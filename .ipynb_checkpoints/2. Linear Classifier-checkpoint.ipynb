{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least Square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\min_\\beta ||A\\beta - y||^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where $A$ is the design matrix. Is a $n \\times (p+1)$ matrix where each column is a feature and each row is an observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "1 & x_1^1 & x_2^1 & \\cdots & x_p^1 \\\\\n",
    "1 & x_1^2 & x_2^2 & \\cdots & x_p^2\\\\\n",
    "\\vdots & \\vdots & \\vdots && \\vdots\\\\\n",
    "1 & x_1^n & x_2^n & \\cdots & x_p^n\\\\\n",
    "\\end{matrix}\n",
    "\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordinary least squares is used to find linear coefficients with help of iris dataset.\n",
    "\n",
    "# \"Sepal.Length\" and \"Petal.Width\" columns are used to predict \"Petal.Length\"\n",
    "A = iris[ , c(\"Sepal.Length\", \"Petal.Width\") ]\n",
    "\n",
    "# 1s is used as column for the intercept coefficient\n",
    "A[ , 'intercept'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = iris[ , \"Petal.Length\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = as.matrix(A)\n",
    "Y = as.matrix(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For statisticians, solving the least squares is usaully via\n",
    "\n",
    "$$\n",
    "\\hat{\\beta} = A^\\dagger y\n",
    "$$\n",
    "\n",
    "where $A^\\dagger$ is the pseudoinverse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pseudoinverse is $A^\\dagger = (A^\\top A) ^{-1} A^\\top$ when $A$ is full rank, otherwsie it is also defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols1 = ( solve( t(A) %*% A ) %*% t(A) ) %*% Y\n",
    "ols1\n",
    "\n",
    "# comparing it with lm function\n",
    "lm(Petal.Length ~ Sepal.Length + Petal.Width, data=iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\nabla(\\beta) = 2 A^\\top(A \\beta - y).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001  # learning rate\n",
    "b = runif(3) # random starting points for beta\n",
    "bh = t(b) # bh stores value of betas for each iteration\n",
    "for (i in 1:100000) {\n",
    "    gradient = 2 * t(A) %*% ( (A %*% b) - Y ) # calculate gradient\n",
    "    b = b - lr * gradient # update beta\n",
    "    bh = rbind(bh, t(b)) # store beta to bh\n",
    "}\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Error for each combination of $\\beta$ through gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating $\\sum (\\hat{y}-y)^2 $ for each $\\beta$ combination of gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = colSums((A %*% t(bh) - as.vector(Y))^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the coefficients (in the 3 axes) - with error as color\n",
    "\n",
    "gradientData = data.frame(bh, error=error)\n",
    "\n",
    "library('plotly')\n",
    "fig <- plot_ly(gradientData, x = ~Sepal.Length, y = ~Petal.Width, z = ~intercept, type = 'scatter3d', mode = 'lines',\n",
    "        opacity = 1, line = list(width = 6, color = ~error, reverscale = FALSE))\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now the discussion goes into MNIST\n",
    "MNIST contain 28 X 28 pixels hand-written digits like the below.<br>\n",
    "$28\\times 28 = 784$ features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"img/MNIST.png\" width=\"200\" align=\"center\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library('keras')\n",
    "library('MASS') # package to calculate pseudo inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist <- dataset_mnist() # loading data -- function present in keras package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mnist dataset contains a training set and a test set.<br>\n",
    "\"$x$\" and \"$y$\" are explanatory and response variables in each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist$train$x[1,,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the 1st digit of MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(\"plot.matrix\")\n",
    "plot(mnist$train$x[1,,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flattening 28 X 28 pixels\n",
    "\n",
    "A <- array_reshape( mnist$train$x, c(dim(mnist$train$x)[1], 784) )\n",
    "dim(A)\n",
    "head(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding 1s as a feature for the intercept term\n",
    "\n",
    "A = cbind(matrix(rep(1, nrow(A))), A)\n",
    "dim(A)\n",
    "head(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # The response variable is the digit number varying from 0 to 9.\n",
    " \n",
    "table(mnist$train$y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_categorical function is used to create binary matrix from categorical data.\n",
    "# However it requires the categorical data to be numbered starting from 0. else it will create '0' columns for number from 0 until the minimum value of categorical column.\n",
    "\n",
    "to_categorical(0:2)\n",
    "to_categorical(1:3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the response column to binary class matrix\n",
    "\n",
    "Y = to_categorical(mnist$train$y) \n",
    "head(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional - replacing 0 with -1\n",
    "\n",
    "Y[Y==0] = -1\n",
    "dim(Y)\n",
    "head(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{\\beta} = A^\\dagger y\n",
    "$$\n",
    "\n",
    "where $A^\\dagger$ is the pseudoinverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudoInv = ginv(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pseudoInv %*% Y\n",
    "dim(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(b[,9], ylim=c(-.2,.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{y} = A \\hat{\\beta}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = A %*% b\n",
    "head(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"pred\" is a number proportional to the possibility of an instance belonging to a digit. \n",
    "# we classify the instance into that class which is maximum \n",
    "\n",
    "table(mnist$train$y, apply(pred, 1, which.max)-1)   #  confusion matrix\n",
    "mean(mnist$train$y == apply(pred, 1, which.max)-1)  #  train accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redoing the same steps to calculate test error\n",
    "\n",
    "A <- array_reshape( mnist$test$x, c(dim(mnist$test$x)[1], 784) )\n",
    "A = cbind(matrix(rep(1, nrow(A))), A)\n",
    "pred = A %*% b\n",
    "\n",
    "table(mnist$test$y, apply(pred, 1, which.max)-1)\n",
    "mean(mnist$test$y == apply(pred, 1, which.max)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myClassifier = function(img) {\n",
    "#     convert img to vector\n",
    "#     append intercept\n",
    "#     multiply by trained weights\n",
    "#     choose which max\n",
    "#     return predicted digit\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a function which takes as argument an image, and returns the digit predicted using the trained $\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myClassifier = function(img) {\n",
    "\n",
    "    # convert img to vector\n",
    "    A <- array_reshape( img, c(1, 784) )\n",
    "    \n",
    "    # append intercept\n",
    "    A = cbind(matrix(rep(1, nrow(A))), A)\n",
    "\n",
    "    # multiply by trained weights\n",
    "    pred = A %*% b\n",
    "    \n",
    "    # choose which max\n",
    "    predDigit = apply(pred, 1, which.max)-1\n",
    "    \n",
    "    return(predDigit)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting a digit using the classifier udf\n",
    "\n",
    "myClassifier(mnist$train$x[1,,])\n",
    "mnist$train$y[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST Prediction using Gradient Descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library('plotly')\n",
    "\n",
    "A <- array_reshape( mnist$train$x, c(dim(mnist$train$x)[1], 784) )\n",
    "A = cbind(matrix(rep(1, nrow(A))), A)\n",
    "\n",
    "Y = to_categorical(mnist$train$y)\n",
    "Y[Y==0] = -1 # optional\n",
    "\n",
    "\n",
    "lr = 0.00001 \n",
    "b = matrix(runif(ncol(A)*ncol(Y)), ncol=ncol(Y)) ;\n",
    "for (i in 1:10) {\n",
    "    gradient = 2 * t(A) %*% ( (A %*% b) - Y )\n",
    "    b = b - lr * gradient\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
